**Key Features:**

Data Preprocessing: Encoding categorical variables, scaling numerical features.

Classification Models: Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree.

Regression Trees: Optional analysis with Boston/California Housing dataset.

**Model Evaluation:**

Train-test split vs cross-validation for stability analysis.

F1 score calculation for multiple hyperparameter settings.

Bias-variance interpretation based on model complexity.

**Experiments:**

KNN with k = 1,3,5,7,9,11

Decision Tree with max_depth = 2,4,6,8,None

Pipeline with StandardScaler + Logistic Regression

**Visualization:**

F1 score trends for different hyperparameters

Decision Tree structure visualization

Bias-variance behavior interpretation

**Learning Outcomes:**

Understanding underfitting and overfitting in KNN and Decision Trees.

How scaling affects Logistic Regression performance.

Importance of cross-validation for reliable evaluation.

Hands-on experience in model selection and reporting insights.

Technologies:
Python | pandas | scikit-learn | matplotlib | numpy
